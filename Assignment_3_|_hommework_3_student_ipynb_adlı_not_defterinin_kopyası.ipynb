{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erhansozen/Assignments-LearningPortfolio/blob/main/Assignment_3_%7C_hommework_3_student_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "HhmY7I5M8VJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Artificial Neural Networks\n",
        "\n",
        "Please read the introdcution of neuronal networks of the book *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*, p. 299-316.\n",
        "\n",
        "❓ Why have neural networks, even though they were invented early on, only now caught on?\n",
        "\n",
        "✈\n",
        "\n",
        "\n",
        "❓ What is a percepton and a threshold logic unit (TLU)? Try to define a linear function and a step function of your choice, use some values of your choice and explain what might be the result of the percepton. (maybe using max. two TLU's)\n",
        "\n",
        "✈ Perception is one of the simplest Artificial Neural Network architectures. It is based on a slightly different artificial neuron called Threshold Logic Unit (TLU).\n",
        "\n",
        "❓ What is a fully connected layer and a output layer? Why can we easily combine the equations of multiple instances into a fully connected layer?\n",
        "\n",
        "✈ A perceptron is composed of one or more TLUs organized in a single layer, where every TLU is connected to every input. This layer is called a FULLY CONNECTED LAYER. TLUs layer that gives the outputs is called output layer. SYF 333'de sayfanın alt kısmında cevap\n",
        "\n",
        "❓ What problem did Marvin Minsky and Seymour Paper highlight that perceptrons could not solve? What is a possible solution?\n",
        "\n",
        "✈ They figured out the incapable of solving some trivial problems classification problem of perfecptrons. Then they find out perceptrons turn out that some of the limitations of perceptrons can be eliminated by stacking multiple perceptrons. This ANN architecture is called a MULTILAYER PERCEPTRONS (MLP)\n",
        "\n",
        "❓ What is a deep neuronal network? What are hidden layers? What means feedforward neural network (FNN).\n",
        "\n",
        "✈This multilayer perceptrons (MLP) are consist of one input layer and one or more layers of TLUs, and they are called HIDDEN LAYERS. When an ANN contains a deep stack of hidden layers, it is called a DEEP NEURAL NETWORK (DNN)\n",
        "\n",
        "\n",
        "❓ Try to explain how backpropagation works! (In Addition, you can have a look to the following example, which tries manually to compute the backprogation of a simple linear network. https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ OR you can also read through the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy))\n",
        "\n",
        "✈ Backpropagation is combined with reverse-mode autodifferentiation and gradient descent. Reverse-mode autodiff is a technique that compute all the gradients automatically and efficently. Two passes through the neural network is able to compute the gradients of the neural network's error with regard to every single model parameter. These gradients can be used to perform a gradients descent step. Then you repeat this process of computing the gradients automatically and taking a gradient descent step, the neural network's error will gradually drop until it eventually reaches a minimum. This combination of reverse-mode auto diff and gradient descent is called BACKPROPAGATION.\n",
        "\n",
        "\n",
        "❓ Why do we need activation functions, wouldn't it be easier just using linear functions?\n",
        "\n",
        "✈ Backpropagation algorithm works well with activation functions. If you have some nonlinearity between layers, then even a deep stack of layers is equivalent to a single layer and you can't solve very complex problems with that.\n",
        "\n",
        "\n",
        "## Ideas for the learning portfolio: \n",
        "\n",
        "1) For example, you could train a single TLU to classify iris flowers based on petal length and width in the !!!pyTorch!! environment.\n",
        "\n",
        "2) You could add to our king county housepricing ML project a neuronal network and compare it to the other models. "
      ],
      "metadata": {
        "id": "_Rdj49uwjuoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "4tF8YDV3T91n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A traditional approach: training a digit classifier and learning pyTorch tensors.\n",
        "\n",
        "For this assignment, I ask you to read the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy) to the beginning of the chapter *Stochastic Gradient Descent (SGD)*. \n",
        "\n",
        "First, try to summarize what we know about pyTorch tensors by trying to predict whether we have a 1 or a 7 in the MNIST dataset using a traditional rule-based programming approach. Therefore use pyTorch tensors for the entire tasks and fulfill the following steps:\n",
        "\n",
        "1) Randomly split the MNIST dataset (1 and 7) into a training dataset and a test dataset in a ratio of 80:20.\n",
        "\n",
        "2) Instead of using an optimal 1 or 7 with the mean over the training dataset, try to calculate the sum of the distances to all instances in the training set for each instance in the test dataset. You can use the L2 norm. \n",
        "\n",
        "3) For each instance in the test set, decide if it is a 1 or 7 and calculate the precision.\n",
        "\n",
        "Do we get a similar good result?\n"
      ],
      "metadata": {
        "id": "h6OwXNEeed93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hrrgv9OVebAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d0f4be15-785b-467e-e9ab-1ba01149a575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# YOUR TASK\n",
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')\n",
        "path = untar_data(URLs.MNIST_SAMPLE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path\n",
        "path.ls()\n",
        "(path/'train').ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4a06y5PYNr6",
        "outputId": "ceabc501-6322-465f-e663-d8891ba12c3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('train/7'),Path('train/3')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()\n",
        "threes"
      ],
      "metadata": {
        "id": "aE0GItfVYXpG",
        "outputId": "a5df4f81-eb93-4cd0-fec3-729705dd9b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im3_path = threes[1]\n",
        "im3 = Image.open(im3_path)\n",
        "im3"
      ],
      "metadata": {
        "id": "5fLrU_dZYcEs",
        "outputId": "bce9be0c-ee48-4fb4-cd4a-dab42e0460dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent (SGD)\n",
        "\n",
        "For this exercise I ask you to read the chapter Stochastic Gradient Descent (SGD) from the Google Colab 04_mnist_basics.ipynb in paralell. The chapter starts with a single TLU, compare p. 304 in \"Hands on Machine Learning\". Go through all 7 steps which are an easy example of how Stochastic Gradient Descent works.\n",
        "\n",
        "Our goal is to train a single TLU, which can decide if one number is larger then the other one. Therefore we create 100 random pairs with pyTorch and create a target vector which is eather 1 or 0.\n"
      ],
      "metadata": {
        "id": "ETcE9B9rdcEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((100, 2))\n",
        "y = torch.where(x[:,0] > x[:,1], 1.0, 0.0)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "17qLyDnbpSbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a51cff4-5e33-400a-9dbf-879743f4ee93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.9269e+00,  1.4873e+00],\n",
            "        [ 9.0072e-01, -2.1055e+00],\n",
            "        [ 6.7842e-01, -1.2345e+00],\n",
            "        [-4.3067e-02, -1.6047e+00],\n",
            "        [-7.5214e-01,  1.6487e+00],\n",
            "        [-3.9248e-01, -1.4036e+00],\n",
            "        [-7.2788e-01, -5.5943e-01],\n",
            "        [-7.6884e-01,  7.6245e-01],\n",
            "        [ 1.6423e+00, -1.5960e-01],\n",
            "        [-4.9740e-01,  4.3959e-01],\n",
            "        [-7.5813e-01,  1.0783e+00],\n",
            "        [ 8.0080e-01,  1.6806e+00],\n",
            "        [ 1.2791e+00,  1.2964e+00],\n",
            "        [ 6.1047e-01,  1.3347e+00],\n",
            "        [-2.3162e-01,  4.1759e-02],\n",
            "        [-2.5158e-01,  8.5986e-01],\n",
            "        [-1.3847e+00, -8.7124e-01],\n",
            "        [-2.2337e-01,  1.7174e+00],\n",
            "        [ 3.1888e-01, -4.2452e-01],\n",
            "        [ 3.0572e-01, -7.7459e-01],\n",
            "        [-1.5576e+00,  9.9564e-01],\n",
            "        [-8.7979e-01, -6.0114e-01],\n",
            "        [-1.2742e+00,  2.1228e+00],\n",
            "        [-1.2347e+00, -4.8791e-01],\n",
            "        [-9.1382e-01, -6.5814e-01],\n",
            "        [ 7.8024e-02,  5.2581e-01],\n",
            "        [-4.8799e-01,  1.1914e+00],\n",
            "        [-8.1401e-01, -7.3599e-01],\n",
            "        [-1.4032e+00,  3.6004e-02],\n",
            "        [-6.3477e-02,  6.7561e-01],\n",
            "        [-9.7807e-02,  1.8446e+00],\n",
            "        [-1.1845e+00,  1.3835e+00],\n",
            "        [ 1.4451e+00,  8.5641e-01],\n",
            "        [ 2.2181e+00,  5.2317e-01],\n",
            "        [ 3.4665e-01, -1.9733e-01],\n",
            "        [-1.0546e+00,  1.2780e+00],\n",
            "        [-1.7219e-01,  5.2379e-01],\n",
            "        [ 5.6622e-02,  4.2630e-01],\n",
            "        [ 5.7501e-01, -6.4172e-01],\n",
            "        [-2.2064e+00, -7.5080e-01],\n",
            "        [ 1.0868e-02, -3.3874e-01],\n",
            "        [-1.3407e+00, -5.8537e-01],\n",
            "        [ 5.3619e-01,  5.2462e-01],\n",
            "        [ 1.1412e+00,  5.1644e-02],\n",
            "        [ 7.4395e-01, -4.8158e-01],\n",
            "        [-1.0495e+00,  6.0390e-01],\n",
            "        [-1.7223e+00, -8.2777e-01],\n",
            "        [ 1.3347e+00,  4.8354e-01],\n",
            "        [-2.5095e+00,  4.8800e-01],\n",
            "        [ 7.8459e-01,  2.8647e-02],\n",
            "        [ 6.4076e-01,  5.8325e-01],\n",
            "        [ 1.0669e+00, -4.5015e-01],\n",
            "        [-1.8527e-01,  7.5276e-01],\n",
            "        [ 4.0476e-01,  1.7847e-01],\n",
            "        [ 2.6491e-01,  1.2732e+00],\n",
            "        [-1.3109e-03, -3.0360e-01],\n",
            "        [-1.4570e+00, -1.0234e-01],\n",
            "        [-5.9915e-01,  4.7706e-01],\n",
            "        [ 7.2618e-01,  9.1152e-02],\n",
            "        [-3.8907e-01,  5.2792e-01],\n",
            "        [-1.2685e-02,  2.4084e-01],\n",
            "        [ 1.3254e-01,  7.6424e-01],\n",
            "        [ 1.0950e+00,  3.3989e-01],\n",
            "        [ 7.1997e-01,  4.1141e-01],\n",
            "        [ 1.9312e+00,  1.0119e+00],\n",
            "        [-1.4364e+00, -1.1299e+00],\n",
            "        [-1.3603e-01,  1.6354e+00],\n",
            "        [ 6.5474e-01,  5.7600e-01],\n",
            "        [ 1.1415e+00,  1.8565e-02],\n",
            "        [-1.8058e+00,  9.2543e-01],\n",
            "        [-3.7534e-01,  1.0331e+00],\n",
            "        [-6.8665e-01,  6.3681e-01],\n",
            "        [-9.7267e-01,  9.5846e-01],\n",
            "        [ 1.6192e+00,  1.4506e+00],\n",
            "        [ 2.6948e-01, -2.1038e-01],\n",
            "        [-7.3280e-01,  1.0430e-01],\n",
            "        [ 3.4875e-01,  9.6759e-01],\n",
            "        [-4.6569e-01,  1.6048e+00],\n",
            "        [-2.4801e+00, -4.1754e-01],\n",
            "        [-1.1955e+00,  8.1234e-01],\n",
            "        [-1.9006e+00,  2.2858e-01],\n",
            "        [ 2.4859e-02, -3.4595e-01],\n",
            "        [ 2.8683e-01, -7.3084e-01],\n",
            "        [ 1.7482e-01, -1.0939e+00],\n",
            "        [-1.6022e+00,  1.3529e+00],\n",
            "        [ 1.2888e+00,  5.2295e-02],\n",
            "        [-1.5469e+00,  7.5671e-01],\n",
            "        [ 7.7552e-01,  2.0265e+00],\n",
            "        [ 3.5818e-02,  1.2059e-01],\n",
            "        [-8.0566e-01, -2.0758e-01],\n",
            "        [-9.3195e-01, -1.5910e+00],\n",
            "        [-1.1360e+00, -5.2260e-01],\n",
            "        [-1.5933e-01, -4.2494e-01],\n",
            "        [ 9.4423e-01, -1.8493e-01],\n",
            "        [ 1.0608e+00,  2.0830e-01],\n",
            "        [-5.7785e-01,  3.2546e-01],\n",
            "        [ 2.6178e-01, -7.5993e-01],\n",
            "        [-2.0461e+00, -1.5295e+00],\n",
            "        [ 4.0487e-01,  6.3188e-01],\n",
            "        [ 3.1253e-01, -3.3502e-02]])\n",
            "tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        1., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to create a function f that is a single TLU, meaning that it summarizes x with weights a, b, c:\n",
        "\n",
        "$ax_0+bx_1+c$\n",
        "\n",
        "In Addition we are using a *sigmoid()* function as step function.\n",
        "\n",
        "$f = \\text{sigmoid}(ax_0+bx_1+c)$"
      ],
      "metadata": {
        "id": "z267w4G48rxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✈ We want to distinguish clearly between the function's input (the time when we are measuring the coaster's speed) and its parameters (the values that define which quadratic we're trying). So, let's collect the parameters in one argument and thus separate the input, t, and the parameters, params, in the function's signature\n",
        "\n",
        "✈ In other words, we've restricted the problem of finding the best imaginable function that fits the data, to finding the best quadratic function. This greatly simplifies the problem, since every quadratic function is fully defined by the three parameters a, b, and c. Thus, to find the best quadratic function, we only need to find the best values for a, b, and c."
      ],
      "metadata": {
        "id": "0v4noXQnnqCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, params):\n",
        "    a,b,c = params\n",
        "    return a*(x**2) + (b*x) + c\n",
        "\n",
        "print(f(x, [3,-2,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NvBnCGoLPx",
        "outputId": "1d6ab2be-e4c0-4ecf-e1ed-3fc437e5d2c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8.2852,  4.6615],\n",
            "        [ 1.6324, 18.5107],\n",
            "        [ 1.0239,  8.0414],\n",
            "        [ 1.0917, 11.9342],\n",
            "        [ 4.2014,  5.8574],\n",
            "        [ 2.2471,  9.7176],\n",
            "        [ 4.0452,  3.0577],\n",
            "        [ 4.3110,  1.2191],\n",
            "        [ 5.8070,  1.3956],\n",
            "        [ 2.7370,  0.7005],\n",
            "        [ 4.2406,  2.3317],\n",
            "        [ 1.3222,  6.1122],\n",
            "        [ 3.3502,  3.4493],\n",
            "        [ 0.8971,  3.6751],\n",
            "        [ 1.6242,  0.9217],\n",
            "        [ 1.6930,  1.4984],\n",
            "        [ 9.5213,  5.0196],\n",
            "        [ 1.5964,  6.4133],\n",
            "        [ 0.6673,  2.3897],\n",
            "        [ 0.6690,  4.3492],\n",
            "        [11.3932,  1.9826],\n",
            "        [ 5.0816,  3.2864],\n",
            "        [ 8.4187, 10.2731],\n",
            "        [ 8.0424,  2.6900],\n",
            "        [ 5.3329,  3.6157],\n",
            "        [ 0.8622,  0.7778],\n",
            "        [ 2.6904,  2.8753],\n",
            "        [ 4.6158,  4.0970],\n",
            "        [ 9.7138,  0.9319],\n",
            "        [ 1.1390,  1.0181],\n",
            "        [ 1.2243,  7.5184],\n",
            "        [ 7.5785,  3.9755],\n",
            "        [ 4.3750,  1.4875],\n",
            "        [11.3234,  0.7748],\n",
            "        [ 0.6672,  1.5115],\n",
            "        [ 6.4457,  3.3438],\n",
            "        [ 1.4333,  0.7755],\n",
            "        [ 0.8964,  0.6926],\n",
            "        [ 0.8419,  3.5189],\n",
            "        [20.0174,  4.1927],\n",
            "        [ 0.9786,  2.0217],\n",
            "        [ 9.0736,  3.1987],\n",
            "        [ 0.7901,  0.7764],\n",
            "        [ 2.6246,  0.9047],\n",
            "        [ 1.1725,  2.6589],\n",
            "        [ 6.4031,  0.8863],\n",
            "        [13.3435,  4.7111],\n",
            "        [ 3.6749,  0.7344],\n",
            "        [24.9125,  0.7384],\n",
            "        [ 1.2776,  0.9452],\n",
            "        [ 0.9502,  0.8540],\n",
            "        [ 2.2811,  2.5082],\n",
            "        [ 1.4735,  1.1944],\n",
            "        [ 0.6820,  0.7386],\n",
            "        [ 0.6807,  3.3165],\n",
            "        [ 1.0026,  1.8837],\n",
            "        [10.2829,  1.2361],\n",
            "        [ 3.2753,  0.7286],\n",
            "        [ 1.1296,  0.8426],\n",
            "        [ 2.2322,  0.7803],\n",
            "        [ 1.0259,  0.6923],\n",
            "        [ 0.7876,  1.2237],\n",
            "        [ 2.4071,  0.6668],\n",
            "        [ 1.1151,  0.6850],\n",
            "        [ 8.3258,  2.0479],\n",
            "        [10.0626,  7.0895],\n",
            "        [ 1.3276,  5.7529],\n",
            "        [ 0.9766,  0.8433],\n",
            "        [ 2.6261,  0.9639],\n",
            "        [14.3944,  1.7184],\n",
            "        [ 2.1733,  2.1356],\n",
            "        [ 3.7878,  0.9430],\n",
            "        [ 5.7836,  1.8390],\n",
            "        [ 5.6270,  4.4116],\n",
            "        [ 0.6789,  1.5535],\n",
            "        [ 4.0766,  0.8240],\n",
            "        [ 0.6674,  1.8735],\n",
            "        [ 2.5820,  5.5165],\n",
            "        [24.4132,  2.3581],\n",
            "        [ 7.6782,  1.3550],\n",
            "        [15.6374,  0.6996],\n",
            "        [ 0.9521,  2.0509],\n",
            "        [ 0.6732,  4.0641],\n",
            "        [ 0.7420,  6.7779],\n",
            "        [11.9051,  3.7852],\n",
            "        [ 3.4056,  0.9036],\n",
            "        [11.2719,  1.2044],\n",
            "        [ 1.2533,  9.2675],\n",
            "        [ 0.9322,  0.8024],\n",
            "        [ 4.5586,  1.5444],\n",
            "        [ 5.4695, 11.7755],\n",
            "        [ 7.1433,  2.8645],\n",
            "        [ 1.3948,  2.3916],\n",
            "        [ 1.7863,  1.4725],\n",
            "        [ 2.2543,  0.7136],\n",
            "        [ 3.1574,  0.6669],\n",
            "        [ 0.6820,  4.2524],\n",
            "        [17.6523, 11.0766],\n",
            "        [ 0.6820,  0.9341],\n",
            "        [ 0.6680,  1.0704]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to our TLU function, we need a loss function. Your task is to implement a absolute difference loss function, $∑|x_i-y_i|$, which counts the number of wrong guesses."
      ],
      "metadata": {
        "id": "UBiKkGKx-jVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, targets): return ((preds-targets)**2).mean()"
      ],
      "metadata": {
        "id": "cwzyy281wI7Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to train your single TLU with the absolute difference loss function, use the following code. Choose an appropriate step weight `lr` and try to explain what is happing in each line."
      ],
      "metadata": {
        "id": "eGVNErmbvFxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1\n",
        "params = torch.randn(3).requires_grad_()\n",
        "\n",
        "def apply_step(params, prn=True):\n",
        "    preds = f(x, params)\n",
        "    loss = mae(preds, y)\n",
        "    loss.backward()\n",
        "    params.data -= lr * params.grad.data\n",
        "    params.grad = None\n",
        "    if prn: print(params);print(loss.item())\n",
        "    return preds\n",
        "\n",
        "\n",
        "for i in range(50): apply_step(params)"
      ],
      "metadata": {
        "id": "EB5TYTNmyO3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "41cc5f77-dfe0-4b7c-903c-2473503fe3f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6ebbf22eaffa>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-6ebbf22eaffa>\u001b[0m in \u001b[0;36mapply_step\u001b[0;34m(params, prn)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-60726b3fc79e>\u001b[0m in \u001b[0;36mmae\u001b[0;34m(preds, targets)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (100) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a line of code that counts the number of wrong predictions, rounding your predictions with *round()*."
      ],
      "metadata": {
        "id": "h5_LNc1o_o2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = f(x, params)\n",
        "preds.round()"
      ],
      "metadata": {
        "id": "EEUhyhyDxwMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f263ef7-4d8d-4b48-dc10-98491cfcbd74"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  1.],\n",
              "        [ 1., -6.],\n",
              "        [ 1., -3.],\n",
              "        [-0., -4.],\n",
              "        [-2.,  1.],\n",
              "        [-1., -3.],\n",
              "        [-1., -1.],\n",
              "        [-2.,  1.],\n",
              "        [ 1., -0.],\n",
              "        [-1.,  1.],\n",
              "        [-2.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [-0.,  0.],\n",
              "        [-0.,  1.],\n",
              "        [-3., -2.],\n",
              "        [-0.,  1.],\n",
              "        [ 0., -1.],\n",
              "        [ 0., -2.],\n",
              "        [-4.,  1.],\n",
              "        [-2., -1.],\n",
              "        [-3.,  1.],\n",
              "        [-3., -1.],\n",
              "        [-2., -1.],\n",
              "        [ 0.,  1.],\n",
              "        [-1.,  1.],\n",
              "        [-2., -1.],\n",
              "        [-3.,  0.],\n",
              "        [-0.,  1.],\n",
              "        [-0.,  1.],\n",
              "        [-3.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1., -0.],\n",
              "        [-2.,  1.],\n",
              "        [-0.,  1.],\n",
              "        [ 0.,  1.],\n",
              "        [ 1., -1.],\n",
              "        [-6., -2.],\n",
              "        [ 0., -1.],\n",
              "        [-3., -1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  0.],\n",
              "        [ 1., -1.],\n",
              "        [-2.,  1.],\n",
              "        [-4., -2.],\n",
              "        [ 1.,  1.],\n",
              "        [-7.,  1.],\n",
              "        [ 1.,  0.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1., -1.],\n",
              "        [-0.,  1.],\n",
              "        [ 1.,  0.],\n",
              "        [ 0.,  1.],\n",
              "        [ 0., -1.],\n",
              "        [-3., -0.],\n",
              "        [-1.,  1.],\n",
              "        [ 1.,  0.],\n",
              "        [-1.,  1.],\n",
              "        [-0.,  0.],\n",
              "        [ 0.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [-3., -2.],\n",
              "        [-0.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 1.,  0.],\n",
              "        [-5.,  1.],\n",
              "        [-1.,  1.],\n",
              "        [-1.,  1.],\n",
              "        [-2.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 0., -0.],\n",
              "        [-1.,  0.],\n",
              "        [ 1.,  1.],\n",
              "        [-1.,  1.],\n",
              "        [-7., -1.],\n",
              "        [-3.,  1.],\n",
              "        [-5.,  0.],\n",
              "        [ 0., -1.],\n",
              "        [ 0., -1.],\n",
              "        [ 0., -2.],\n",
              "        [-4.,  1.],\n",
              "        [ 1.,  0.],\n",
              "        [-4.,  1.],\n",
              "        [ 1.,  1.],\n",
              "        [ 0.,  0.],\n",
              "        [-2., -0.],\n",
              "        [-2., -4.],\n",
              "        [-2., -1.],\n",
              "        [-0., -1.],\n",
              "        [ 1., -0.],\n",
              "        [ 1.,  0.],\n",
              "        [-1.,  1.],\n",
              "        [ 0., -2.],\n",
              "        [-5., -4.],\n",
              "        [ 1.,  1.],\n",
              "        [ 0., -0.]], grad_fn=<RoundBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMOaB8-pqILF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}